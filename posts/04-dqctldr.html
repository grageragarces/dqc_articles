<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>DQC State of the Art Today: the TLDR Overview</title>
  <link rel="stylesheet" href="../style.css" />
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      },
      svg: { fontCache: 'global' }
    };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" async></script>
</head>
<body>
  <article>
    <h1>DQC State of the Art Today: the TLDR Overview</h1>
    <p><em>14th of October 2025</em></p>

    <p>
    In just seven years, DQC went from theoretical sketches to experimental claims of distribution, though we are still far from practical DQC. 
    This post lists what is missing, what we have, and what you can actually try today.  
    </p>

    <p><a href="../index.html">‚Üê Back to all posts</a></p>

<section>

  Distributed quantum computing is young.  
  The first theoretical papers appeared around 2018, and already we have experimental claims of distribution.  
  Xanadu's Aurora, announced about a year ago, was the first claim of a distributed quantum computer.  
  The device itself has not been publicly released, but its photonic architecture is interesting because photons are the flying qubits that naturally carry quantum information between modules.  
  In a sense, photonic quantum computers are distributed by design.  
  You can move atoms or ions between locations by optical transport, but that approach is unlikely to scale over long distances, which is why most visions of quantum networking rely on photons as the carriers of entanglement.  
  Oxford's recent experiment claiming a distributed algorithm (technically a teleportation between two processors rather than a computation across them) marked another small but meaningful step.  <br>
In just seven years, the field has moved from theoretical sketches to physical demonstrations of distribution.  <br><br>

  Still, we are missing the shared backbone that would let us test these ideas end to end.  
  We have early stage quantum computers and networks, but they rarely meet within a single experimental setup.  
  A real shame, especially given that many institutions hold both under the same roof.
  Given that public distributed testbeds are non-existent, we cannot yet benchmark distributed workloads or reproduce results across groups.  
  This also means that the measurements required to calibrate distributed quantum simulators are non-existent.<br>
  On the other side of the spectrum, compiler stacks that treat communication as a first class resource with explicit costs are few, and even fewer integrate real network models.  
  Error models for quantum channels are scattered and hard to compare across platforms.  
  Orchestration layers that manage heterogeneous devices and track entanglement as a consumable are only starting to appear.    <br><br>

  In other words, we are missing the shared infrastructure and public access that would make distributed quantum computing a testable reality.
  So what are researchers doing in the mean time?
</section>

<section>
  <h2>Emulation and Simulation</h2>

    <div style="background-color:#fff8dc; border-left:4px solid #e6d87c; padding:10px 15px; margin:10px 0;">
  <strong>Emulation</strong> refers to running real quantum programs today while mimicking distribution mechanics.  

  <strong>Simulation</strong> refers to classically modeling quantum devices and networks.  
    </div>

  While we wait for accessible distributed hardware, we can emulate quantum channels through two methods:  <br>

  <ul>
    <li><strong>Knitting:</strong>  
  Today we subcircuits separately and stitch them with classical data.
  This is often known as circuit knitting.  
  Qiskit's cutting addon is perhaps the most popular software package for this.  
  The idea is to run subcircuits sequentially, sample them many times, and feed those measurements as inputs to the next.  
  The method breaks inter partition entanglement and scales poorly, 
  but for a long time it was the only practical option.  <br>

<li><strong>Ladders:</strong>  
  A more recent alternative consists on chaining many CNOT hops between distant regions of a chip, somewhat emulating the role of a noisy quantum link without breaking entanglement. 
  <br>
</ul>


  We also have simulators, often the best worst option. 
  Simulators allow us to model quantum networks and distributed protocols beyond any emulation capacity. 
  They permit us to design and compare protocols, study scaling, and build architectural infrastructure for tomorrow's devices.
  Yet they must always be interpreted with care, especially given that they are not calibrated to real devices.  <br>

  If you want to explore DQC in simulation, these are common choices:  

  <ul>
    <li><a href="https://netsquid.org" target="_blank">NetSquid</a> (TU Delft): considered state of the art for quantum network simulation. Closed source, so internals are not directly inspectable or modifiable unless you collaborate.</li>
    <li><a href="https://github.com/sequence-toolbox/SeQUeNCe" target="_blank">SeQUeNCe</a>(Argonne Labs): an open source counterpart. It models realistic network layers and lets you build distributed protocols from components.</li>
    <li><a href="https://qiskit.github.io/qiskit-addon-cutting/" target="_blank">Qiskit Addon</a>: supports classical emulation of circuit cutting inside Qiskit. Fast to try. Not a physical network simulator.</li>
  </ul>

  Notably, companies seem increasingly interested in distributed compilers.  
  Both Welinq's araQne and Cisco's network-aware compiler have been announced as attempts to link quantum compilation with networking, though neither is publicly available yet.

  Despite the increase in interest, none of these options deliver a public end to end DQC stack, but
  together they cover protocol design, network effects, and compiler informed slicing.  
  But even the best emulations fall short for one main reason: they can't capture how noise behaves in real distributed setups.
</section>

<section>
  <h2>The Noisy Reality</h2>

  Noise is the main reason simulators and emulators fall short.  
  It dominates fidelity and defines whether any distributed computation survives execution.  
  Early studies already show that network channels can inject up to an order of magnitude more loss than local gates and measurements [Campbell et al. 2022]
  , when modeled with the same internal noise levels.  
  The difference comes from how network noise behaves: it depends on distance, link quality, timing, and how qubits are moved or entangled across space.  
  That spatial dependence cannot be emulated within a single chip, which makes calibration against real hardware impossible for now.  
  <br><br>

  A second challenge is heterogeneity.  
  Distributed systems will likely link devices built on entirely different technologies, each with its own strengths and weaknesses.  
  One node might operate with trapped ions and include native error correction; another could use superconducting qubits with faster but noisier gates.  
  Synchronizing these devices means managing multiple noise profiles and aligning control layers that were never designed to talk to each other.  
  We can barely achieve that level of coordination even within monolithic setups.  
  <br><br>

  Finally, all distribution costs reduce to communication.  
  Moving quantum information between modules requires well-defined primitives and clear models of how they affect fidelity and runtime.  
  Two remain central today:  

  <ul>
    <li><strong>TP</strong> (teleportation): transfers quantum states using shared entanglement and classical communication.  
    Under limited capacity, it often behaves like a non-local swap to enable local operations.</li>

    <li><strong>CAT</strong> (gate teleportation): transfers the *action* of a gate using an entangled resource, often a GHZ or cat state.</li>
  </ul>

<figure style="margin-top: 0.5em; text-align: center;">
  <img src="../images/cat_tp.png" alt="CAT and TP primitives" style="height: 200px;">
  <figcaption style="font-size: 0.9em; color: #555;">
    Visual representation of CAT and TP primitive subcircuits used for distributed communication, taken from [Wu et al. 2022].
  </figcaption>
</figure>

  Both primitives are essential but come with trade-offs.  
  Teleportation is simpler but communication-heavy; gate teleportation preserves circuit structure yet amplifies noise.  
  Current research focuses on reducing this overhead and incorporating these trade-offs into compilers that model communication errors explicitly.  
</section>


<section>
  <h2>An open letter to anyone who will read: make a testbed</h2>

  We have theory.  
  We have prototypes.  
  We even have simulators that claim to capture the future.  
  What we do not have is a place to make them meet.  
  A true distributed quantum testbed would change that.  
  It would let us connect real processors, quantify network noise, and check whether our emulations reflect physical reality.  
  It would turn distributed quantum computing from concept to science.  
  <br><br>

  If you are a lab with both a quantum computer and a quantum network, connect them.  
  If you are a company running multiple devices, open a fraction of that infrastructure for research access.  
  If you are funding national or academic programs, make node pairs public.  
  Shared hardware is how we build shared truth.  
  <br><br>

  Until we can execute protocols on connected machines, DQC will remain a theoretical promise.  
  The missing link between vision and validation is a public testbed.  
  Build it (and let me know how it goes).  
</section>

<section>
    <h2>References</h2>
    <ul>
        <li>[Wu et al. 2022] AutoComm: A Framework for Enabling Efficient Communication in Distributed Quantum Programs</li> 
        <li>[Campbell et al. 2022] Quantum data centres: a simulation-based comparative noise analysis</li>
    </ul>
</section>
