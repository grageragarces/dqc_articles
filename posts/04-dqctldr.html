<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>DQC State of the Art Today: the TLDR Overview</title>
  <link rel="stylesheet" href="../style.css" />
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      },
      svg: { fontCache: 'global' }
    };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" async></script>
</head>
<body>
  <article>
    <h1>DQC State of the Art Today: the TLDR Overview</h1>
    <p><em>October 2025</em></p>

    <p>
    In just seven years, DQC went from theoretical sketches to experimental claims of distribution, though we're still far from practical DQC. 
    This blog post offers a concise overview of where we stand today, 
    and what challenges remain before real implementations appear.
    </p>

    <p><a href="../index.html">← Back to all posts</a></p>

<section>
  <h2>Early milestones</h2>
  Distributed quantum computing is still in its early days.  
  The first theoretical papers on the topic only started appearing around 2018.  

  Almost a year ago we saw the first claim of a distributed quantum computer: Xanadu's Aurora.  
  To my knowledge it has never been made publicly accessible.  
  Aurora is a photonic system, and photonic quantum computers are in some sense distributed by design.  
  Photons are the flying qubits that enable quantum communication, so moving information between modules comes naturally in this architecture.  

  You can technically move atoms or ions between locations by “pinching” them photonically, but that approach is unlikely to scale over long distances.  
  For that reason, most visions of quantum networking rely on photons as the carriers of entanglement.  

  We also recently saw a claim from Oxford of the first distributed algorithm.  
  In practice, what they demonstrated was teleportation between two processors, not a computation distributed across them.  
  Still, it marks an experimental milestone: in just seven years, the field has moved from theoretical abstractions to physical demonstrations of distribution.  

  That said, we are still far from practical DQC.  
  There are no publicly accessible testbeds that combine quantum computing and quantum networking.  
  Both exist independently, but not together.  
  Which is a shame, especially for institutions that already host both capabilities under one roof.  

  Given the lack of hardware, what are DQC researchers doing today?  
  That's what we'll explore in this post.
</section>

<section>
  <h2>The shaking heads from HPC experts</h2> 

  A big part of the DQC conversation is how to partition computations for distribution.  
  This is not a new problem; HPC people have been thinking about it for decades.  
  They learned the hard way that splitting large computations across machines is messy.  
  You have to balance load, minimize communication, and somehow keep everything consistent.  

  To understand how this is done, it helps to recall what partitioning means.  
  In both classical and quantum settings, partitioning often starts by representing the computation as a graph or hypergraph.  
  Each node represents a variable or qubit, and edges represent dependencies between them.  
  The goal is to divide the structure into smaller parts that minimize connections between them, because each connection represents costly communication across devices.  

  As systems scale, that becomes harder.  
  You can't realistically cut up a million-qubit computation without huge orchestration overhead.  
  You would need a high-performance computer just to manage your quantum computer.  

  In HPC, people model problems as graphs and use tools like METIS or KaHyPar to decide how to split them with minimal cross-talk.  
  We are now doing the same with quantum circuits, only every cut you make becomes a teleportation or an entangled link, much more expensive than sending classical data.  

  Compilation adds another layer.  
  Exploring all possible optimizations for even a moderately sized quantum circuit is already computationally heavy.  
  Add partitioning and you are staring at an NP-hard search problem.  

  So there is an irony here: distribution is supposed to help scalability, yet solving distribution itself already demands scalable computation.  
  It is an old HPC headache, now with quantum error rates attached.
</section>

<section>
  <h2>How we can emulate distribution today</h2>

  While we wait for actual distributed quantum hardware, researchers can still experiment with aspects of distribution using emulation.  
  Emulation means recreating the behavior of a distributed setup on existing devices or simulators.  

  Since there are no real DQC testbeds yet, what people can do for now is emulate distribution.  
  The most common approach is to run parts of a quantum computation separately, then stitch the results together using classical channels.  

  Qiskit's cutting addon does this quite nicely.  
  You run one subcircuit, sample it many times, and feed those measurement results as inputs to the next subcircuit.  
  This reproduces what communication between two QPUs would do, at least at the level of data flow.  

  The catch is that this process breaks entanglement between partitions.  
  That means it is not physically accurate and, worse, becomes exponentially costly with circuit size.  
  It also does not capture the actual noise that would appear in a real networked setting.  

  Despite that, it is useful.  
  It lets us test distributed algorithms and explore how cutting affects fidelity or runtime before hardware catches up.  
  A few early examples are starting to appear, mostly in simulation papers and small-scale experiments.  

  There is also an avenue for emulating a quantum channel within a single device, basically emulating a channel.  
  The idea is to chain many CNOT hops between two subcomputations that are as physically far apart as possible on the chip.  
  It is not real networking, but it gives a sense of what distribution might look like over quantum channels.
</section>

<section>
  <h2>Errors, errors, errors</h2>

  Over the past few months, these have been dizzying me.  

  The thing with networks is that they do not behave like standalone quantum computers.  
  First, they have completely different error profiles.  
  Second, simulations show they can inject roughly an order of magnitude higher losses into the final fidelity.  
  Third, the effect depends on the communication primitive you use: the noise changes depending on how you move qubits around.  

  In DQC, we are also often talking about different kinds of quantum computers working together.  
  That means heterogeneous noise profiles behaving differently across devices.  
  Some nodes might have local error mitigation baked in, while others do not.  

  For communication primitives, we basically have two options: TP and CAT.  
  TP stands for teleportation, the transfer of quantum states through classical communication and shared entanglement.  
  Under device capacity constraints it is often utilized as a non-local swap, enabling the exchange of qubits to perform localised computations on distanced devices.  

  CAT, on the other hand, stands for gate cutting.  
  Instead of sending a whole state, it effectively teleports the action of a gate.  
  You perform a non-local operation by consuming an entangled resource, often a GHZ or cat state.  
    
  <!-- TODO -->
  <!-- [Image placeholder here for TP vs CAT illustration] -->

  Both TP and CAT are essential for practical DQC, but they come with trade-offs.  
  Teleportation is simpler but communication-heavy, while gate cutting preserves structure but is highly noise-sensitive.  
  Current research is focused on reducing their overheads and integrating them into compilers so that distribution decisions automatically account for error propagation and noise models.
</section>

<section>
  <h2>Simulators, our best worst option</h2>

  Since we cannot yet test distributed setups on real hardware, we end up relying on simulators.  
  And honestly I do not love them.  
  Still, they are the only practical sandbox we have right now.  
  Without simulators, we could not even prototype communication protocols or benchmark distributed algorithms conceptually.  

  Especially the ones not based on real device data.  
  They can be useful, but they often give a false sense of performance or noise behavior.  
  For DQC this is a real problem: there are no testbeds, no experimental data, and no real networks to benchmark against.  
  So you have to simulate.  

  If you want to explore DQC today, these are your main options:  

  <ul>
    <li><strong>NetSquid</strong> (TU Delft): considered state of the art for quantum network simulation. Closed-source, which means you cannot inspect or modify the internals; it is a black box unless you collaborate with the team.</li>
    <li><strong>SeQUeNCe</strong>: the main open-source counterpart. It models realistic network layers and lets you build distributed protocols from scratch.</li>
    <li><strong>Cisco</strong>: claims to have a network-aware distributed quantum compiler. It is not public, but conceptually very interesting, one of the few industrial efforts linking compilation to networking.</li>
    <li><strong>Qiskit Addon</strong>: lets you emulate circuit cutting classically within Qiskit, which is great for quick experiments, though it does not reproduce real entanglement or noise.</li>
    <!-- TODO -->
    <!-- <li><strong>Wellinq's compiler</strong>: shared by Kristina, another tool exploring compilation across modular architectures.</li> -->
  </ul>

  If you are a researcher working on something else or have a better simulator to recommend, please let me know and I will add it here.
</section>

  </article>
</body>
</html>
